{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Onur_Cayci_A3_Q2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPEmT0bKiGsz2acyDnbyovf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QZcPHCSW-sLa"},"source":["# README\n","\n","- This notebook uses the GPU for CNN."]},{"cell_type":"markdown","metadata":{"id":"36-6h4bq-QTu"},"source":["# Image Classification with Convolution Neural Network (CNN)"]},{"cell_type":"code","metadata":{"id":"muJihrHFab3w","executionInfo":{"status":"ok","timestamp":1604691992261,"user_tz":300,"elapsed":280,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}}},"source":["# get a dataset using pytorch\n","import torch\n","import torchvision\n","from torchvision import transforms\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5,))])\n","\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testLoader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_fQeez48uHE","executionInfo":{"status":"ok","timestamp":1604692012286,"user_tz":300,"elapsed":272,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"fb920aca-be6c-46d8-8ae3-4926361779d7","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Prepare the CNN to run on the GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# print out the device\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WMIFpvJud3Eo","executionInfo":{"status":"ok","timestamp":1604692024143,"user_tz":300,"elapsed":10534,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"3de424b7-0f9c-48c6-ac3b-8824e26c541a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# implement a CNN\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # first convolution layer, 1 input (image), 32 kernels, 3x3\n","        self.conv1 = nn.Conv2d(1, 32, 3)\n","        # second convolution layer, 32 inputs, 64 kernels, 3x3\n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        # third convolution layer, 64 inputs, 64 kernels, 3x3\n","        self.conv3 = nn.Conv2d(64, 64, 3)\n","        # fourth convolution layer, 64 inputs, 64 kernels, 3x3\n","        self.conv4 = nn.Conv2d(64, 64, 3)\n","        # first linear layer with output size of 10\n","        self.fc1 = nn.Linear(4096, 10)\n","    \n","    def forward(self, x):\n","        # first relu activation after first convolution\n","        x = F.relu(self.conv1(x))\n","        # second relu activation after second convolution\n","        x = F.relu(self.conv2(x))\n","        # maxpool layer with kernels 2x2\n","        x = F.max_pool2d(x, (2, 2))\n","        # third relu activation after third convolution\n","        x = F.relu(self.conv3(x))\n","        # fourth relu activation after fourth convolution\n","        x = F.relu(self.conv4(x))\n","        # flattening layer\n","        x = torch.flatten(x, 1, 3)\n","        # linear layer with output size 10\n","        x = self.fc1(x)\n","        return x\n","\n","# initialize the CNN\n","net = Net()\n","# convert the methods to CUDA tensors\n","net.to(device)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=4096, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"14klea8qzvoW","executionInfo":{"status":"ok","timestamp":1604692147450,"user_tz":300,"elapsed":301,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}}},"source":["import torch.optim as optim\n","\n","# Create SGD optimizer with learning rate 0.001\n","optimizer = optim.SGD(net.parameters(), lr=0.001)\n","# Create categorical cross entropy criterion\n","criterion = nn.CrossEntropyLoss()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJKu1Vyt1MjO","executionInfo":{"status":"ok","timestamp":1604693323792,"user_tz":300,"elapsed":161718,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"bf4e754d-e9fa-449a-e7ee-3be8bfe813e4","colab":{"base_uri":"https://localhost:8080/"}},"source":["# train the CNN for 10 epochs\n","for epoch in range(10):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs, data is a list of [inputs, labels]\n","        inputs, labels = data\n","        # send data to the GPU\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 1000 == 999:    # print every 1000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 1000))\n","            running_loss = 0.0\n","\n","print('Finished Training!')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[1,  1000] loss: 0.062\n","[2,  1000] loss: 0.061\n","[3,  1000] loss: 0.058\n","[4,  1000] loss: 0.054\n","[5,  1000] loss: 0.055\n","[6,  1000] loss: 0.052\n","[7,  1000] loss: 0.050\n","[8,  1000] loss: 0.051\n","[9,  1000] loss: 0.049\n","[10,  1000] loss: 0.048\n","Finished Training!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SpNSGdV4GqHt"},"source":["# save the trained model\n","torch.save(net.state_dict(), 'mnist_net.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHiJO0dhHM9O","executionInfo":{"status":"ok","timestamp":1604693446205,"user_tz":300,"elapsed":2480,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"1dd925d2-563d-44c4-fa48-83ad86a32155","colab":{"base_uri":"https://localhost:8080/"}},"source":["# predict the labels of the test images and measure the accuracy\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testLoader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the test images: {correct / total * 100}%')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the test images: 98.32%\n"],"name":"stdout"}]}]}