{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Onur_Cayci_A3_Q2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5q07v5/Kvlju/jBowdKJT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"36-6h4bq-QTu"},"source":["# Image Classification with Convolution Neural Network (CNN)"]},{"cell_type":"code","metadata":{"id":"muJihrHFab3w"},"source":["# get a dataset using pytorch\n","import torch\n","import torchvision\n","from torchvision import transforms\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5,))])\n","\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testLoader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_fQeez48uHE","executionInfo":{"status":"ok","timestamp":1603985136922,"user_tz":240,"elapsed":258,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"fb817701-d00e-4db5-ba5a-a60393c39b08","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Prepare the CNN to run on the GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# print out the device\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WMIFpvJud3Eo","executionInfo":{"status":"ok","timestamp":1603985149686,"user_tz":240,"elapsed":9631,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"9f6e355b-3846-451e-dae5-218fbc2b251a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# implement a CNN\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # first convolution layer, 1 input (image), 32 kernels, 3x3\n","        self.conv1 = nn.Conv2d(1, 32, 3)\n","        # second convolution layer, 32 inputs, 64 kernels, 3x3\n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        # third convolution layer, 64 inputs, 64 kernels, 3x3\n","        self.conv3 = nn.Conv2d(64, 64, 3)\n","        # fourth convolution layer, 64 inputs, 64 kernels, 3x3\n","        self.conv4 = nn.Conv2d(64, 64, 3)\n","        # first linear layer with output size of 10\n","        self.fc1 = nn.Linear(4096, 10)\n","    \n","    def forward(self, x):\n","        # first relu activation after first convolution\n","        x = F.relu(self.conv1(x))\n","        # second relu activation after second convolution\n","        x = F.relu(self.conv2(x))\n","        # maxpool layer with kernels 2x2\n","        x = F.max_pool2d(x, (2, 2))\n","        # third relu activation after third convolution\n","        x = F.relu(self.conv3(x))\n","        # fourth relu activation after fourth convolution\n","        x = F.relu(self.conv4(x))\n","        # flattening layer\n","        x = torch.flatten(x, 1, 3)\n","        # linear layer with output size 10\n","        x = self.fc1(x)\n","        return x\n","\n","# initialize the CNN\n","net = Net()\n","# convert the methods to CUDA tensors\n","net.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=4096, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"14klea8qzvoW"},"source":["import torch.optim as optim\n","\n","# Create SGD optimizer with learning rate 0.001\n","optimizer = optim.SGD(net.parameters(), lr=0.001)\n","# Create categorical cross entropy criterion\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJKu1Vyt1MjO","executionInfo":{"status":"ok","timestamp":1603985308891,"user_tz":240,"elapsed":144062,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"b4287acb-685e-4d2d-f772-d655acca1d0e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# train the CNN for 10 epochs\n","for epoch in range(10):\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs, data is a list of [inputs, labels]\n","        inputs, labels = data\n","        # send data to the GPU\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    print(f'Finished Epoch {epoch+1}')\n","\n","print('Finished Training!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Finished Epoch 1\n","Finished Epoch 2\n","Finished Epoch 3\n","Finished Epoch 4\n","Finished Epoch 5\n","Finished Epoch 6\n","Finished Epoch 7\n","Finished Epoch 8\n","Finished Epoch 9\n","Finished Epoch 10\n","Finished Training!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SpNSGdV4GqHt"},"source":["# save the trained model\n","torch.save(net.state_dict(), 'mnist_net.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHiJO0dhHM9O","executionInfo":{"status":"ok","timestamp":1603985319770,"user_tz":240,"elapsed":2468,"user":{"displayName":"Onur Çaycı","photoUrl":"https://lh3.googleusercontent.com/-6HblNx4oYwM/AAAAAAAAAAI/AAAAAAAABDM/AShCfWveifc/s64/photo.jpg","userId":"02486060326914217010"}},"outputId":"e879298a-379e-4b2b-d536-b791536c6dcd","colab":{"base_uri":"https://localhost:8080/"}},"source":["# predict the labels of the test images and measure the accuracy\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testLoader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the test images: {correct / total * 100}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the test images: 96.85000000000001%\n"],"name":"stdout"}]}]}